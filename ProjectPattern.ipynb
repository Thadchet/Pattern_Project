{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectPattern.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fi_E1eTMity0",
        "outputId": "4839eb4b-1bfc-4845-ded9-d097f4565927",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import h5py\n",
        "import shutil\n",
        "import imgaug as aug\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mimg\n",
        "import imgaug.augmenters as iaa\n",
        "from os import listdir, makedirs, getcwd, remove\n",
        "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "from skimage.io import imread\n",
        "from skimage.transform import resize\n",
        "from keras.models import Sequential, Model\n",
        "from keras.applications.vgg16 import VGG16, preprocess_input\n",
        "from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\n",
        "from keras.layers import GlobalMaxPooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.merge import Concatenate\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "import numpy as np\n",
        "from numpy import argmax\n",
        "\n",
        "color = sns.color_palette()\n",
        "%matplotlib inline\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "print(os.listdir(\"./\"))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "['.config', 'sample_data']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7EBbL40Is9C",
        "colab_type": "code",
        "outputId": "c2293261-f330-4e83-f9b5-6ac36afe00a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EED940L6UeaX",
        "colab_type": "code",
        "outputId": "f223b723-2ed1-4e97-cca3-091a9ca2f954",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lCn4Lz5ciz8e",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Set the seed for hash based operations in python\n",
        "os.environ['PYTHONHASHSEED'] = '0'\n",
        "\n",
        "# Set the numpy seed\n",
        "np.random.seed(111)\n",
        "\n",
        "# Disable multi-threading in tensorflow ops\n",
        "session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
        "\n",
        "# Set the random seed in tensorflow at graph level\n",
        "tf.set_random_seed(111)\n",
        "\n",
        "# Define a tensorflow session with above session configs\n",
        "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
        "\n",
        "# Set the session in keras\n",
        "K.set_session(sess)\n",
        "\n",
        "# Make the augmentation sequence deterministic\n",
        "aug.seed(111)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkaQLvPHIs9K",
        "colab_type": "code",
        "outputId": "25544092-0b54-47cf-dcc8-cfe3ed297a9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "print(os.listdir(\"./drive\"))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['.shortcut-targets-by-id', 'Shared drives', 'My Drive', '.Trash']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSZhWxFxIs9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define path to the data directory\n",
        "data_dir = Path('./drive/My Drive/Pattern Recognition/Dataset/chest_xray')\n",
        "\n",
        "# Path to train directory (Fancy pathlib...no more os.path!!)\n",
        "train_dir = data_dir / 'train'\n",
        "\n",
        "# Path to validation directory\n",
        "val_dir = data_dir / 'val'\n",
        "\n",
        "# Path to test directory\n",
        "test_dir = data_dir / 'test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acDDr1vXIs9Q",
        "colab_type": "code",
        "outputId": "609000c0-2a6e-492c-ffe4-6d9479069782",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# Get the path to the normal and pneumonia sub-directories\n",
        "normal_cases_dir = train_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = train_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# An empty list. We will insert the data into this list in (img_path, label) format\n",
        "train_data = []\n",
        "\n",
        "# Go through all the normal cases. The label for these cases will be 0\n",
        "for img in normal_cases:\n",
        "    train_data.append((img,0))\n",
        "\n",
        "# Go through all the pneumonia cases. The label for these cases will be 1\n",
        "for img in pneumonia_cases:\n",
        "    train_data.append((img, 1))\n",
        "\n",
        "# Get a pandas dataframe from the data we have in our list \n",
        "train_data = pd.DataFrame(train_data, columns=['image', 'label'],index=None)\n",
        "\n",
        "# Shuffle the data \n",
        "train_data = train_data.sample(frac=1.).reset_index(drop=True)\n",
        "\n",
        "# How the dataframe looks like?\n",
        "train_data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drive/My Drive/Pattern Recognition/Dataset/che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drive/My Drive/Pattern Recognition/Dataset/che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drive/My Drive/Pattern Recognition/Dataset/che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drive/My Drive/Pattern Recognition/Dataset/che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drive/My Drive/Pattern Recognition/Dataset/che...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               image  label\n",
              "0  drive/My Drive/Pattern Recognition/Dataset/che...      1\n",
              "1  drive/My Drive/Pattern Recognition/Dataset/che...      1\n",
              "2  drive/My Drive/Pattern Recognition/Dataset/che...      1\n",
              "3  drive/My Drive/Pattern Recognition/Dataset/che...      1\n",
              "4  drive/My Drive/Pattern Recognition/Dataset/che...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az-pOyQ1Is9T",
        "colab_type": "code",
        "outputId": "dac19976-337d-43f1-f5c3-eabcdf2086b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        }
      },
      "source": [
        "# Get the counts for each class\n",
        "cases_count = train_data['label'].value_counts()\n",
        "print(cases_count)\n",
        "\n",
        "# Plot the results \n",
        "plt.figure(figsize=(10,8))\n",
        "sns.barplot(x=cases_count.index, y= cases_count.values)\n",
        "plt.title('Number of cases', fontsize=14)\n",
        "plt.xlabel('Case type', fontsize=12)\n",
        "plt.ylabel('Count', fontsize=12)\n",
        "plt.xticks(range(len(cases_count.index)), ['Normal(0)', 'Pneumonia(1)'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    3875\n",
            "0    1357\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAH0CAYAAABvihqoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuGM2nZqIs9Z",
        "colab_type": "code",
        "outputId": "2259c260-a91f-4c11-8fcc-26ef73c13c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Get the path to the sub-directories\n",
        "normal_cases_dir = val_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = val_dir / 'PNEUMONIA'\n",
        "\n",
        "# Get the list of all the images\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "# List that are going to contain validation images data and the corresponding labels\n",
        "valid_data = []\n",
        "valid_labels = []\n",
        "\n",
        "\n",
        "# Some images are in grayscale while majority of them contains 3 channels. So, if the image is grayscale, we will convert into a image with 3 channels.\n",
        "# We will normalize the pixel values and resizing all the images to 224x224 \n",
        "\n",
        "# Normal cases\n",
        "for img in normal_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = [0]\n",
        "    valid_data.append(img)\n",
        "    valid_labels.append(label)\n",
        "                      \n",
        "# Pneumonia cases        \n",
        "for img in pneumonia_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = [1]\n",
        "    valid_data.append(img)\n",
        "    valid_labels.append(label)\n",
        "    \n",
        "# Convert the list into numpy arrays\n",
        "valid_data = np.array(valid_data)\n",
        "valid_labels = np.array(valid_labels)\n",
        "print(\"Total number of validation examples: \", valid_data.shape)\n",
        "print(\"Total number of labels:\", valid_labels.shape)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of validation examples:  (16, 224, 224, 3)\n",
            "Total number of labels: (16, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir6fdW-qy27V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "352dfbbd-8f24-451e-e1b6-9ad8fe12c904"
      },
      "source": [
        "print(valid_labels[0].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtVey9unIs9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Augmentation sequence \n",
        "seq = iaa.OneOf([\n",
        "    iaa.Fliplr(), # horizontal flips\n",
        "    iaa.Affine(rotate=20), # roatation\n",
        "    iaa.Multiply((1.2, 1.5))]) #random brightness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26zPab_ZIs9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_gen(data, batch_size):\n",
        "    # Get total number of samples in the data\n",
        "    n = len(data)\n",
        "    steps = n//batch_size\n",
        "    \n",
        "    # Define two numpy arrays for containing batch data and labels\n",
        "    batch_data = np.zeros((batch_size, 224, 224, 3), dtype=np.float32)\n",
        "    batch_labels = np.zeros((batch_size,1), dtype=np.float32)\n",
        "\n",
        "    # Get a numpy array of all the indices of the input data\n",
        "    indices = np.arange(n)\n",
        "    \n",
        "    # Initialize a counter\n",
        "    i =0\n",
        "    while True:\n",
        "        np.random.shuffle(indices)\n",
        "        # Get the next batch \n",
        "        count = 0\n",
        "        next_batch = indices[(i*batch_size):(i+1)*batch_size]\n",
        "        for j, idx in enumerate(next_batch):\n",
        "            img_name = data.iloc[idx]['image']\n",
        "            label = data.iloc[idx]['label']\n",
        "              \n",
        "           # read the image and resize\n",
        "            img = cv2.imread(str(img_name))\n",
        "            img = cv2.resize(img, (224,224))\n",
        "            \n",
        "            # check if it's grayscale\n",
        "            if img.shape[2]==1:\n",
        "                img = np.dstack([img, img, img])\n",
        "            \n",
        "            # cv2 reads in BGR mode by default\n",
        "            orig_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            # normalize the image pixels\n",
        "            orig_img = img.astype(np.float32)/255.\n",
        "            \n",
        "            batch_data[count] = orig_img\n",
        "            batch_labels[count] = [label]\n",
        "            \n",
        "            # generating more samples of the undersampled class\n",
        "            if label==0 and count < batch_size-2:\n",
        "                aug_img1 = seq.augment_image(img)\n",
        "                aug_img2 = seq.augment_image(img)\n",
        "                aug_img1 = cv2.cvtColor(aug_img1, cv2.COLOR_BGR2RGB)\n",
        "                aug_img2 = cv2.cvtColor(aug_img2, cv2.COLOR_BGR2RGB)\n",
        "                aug_img1 = aug_img1.astype(np.float32)/255.\n",
        "                aug_img2 = aug_img2.astype(np.float32)/255.\n",
        "\n",
        "                batch_data[count+1] = aug_img1\n",
        "                batch_labels[count+1] = [label]\n",
        "                batch_data[count+2] = aug_img2\n",
        "                batch_labels[count+2] = [label]\n",
        "                count +=2\n",
        "            \n",
        "            else:\n",
        "                count+=1\n",
        "            \n",
        "            if count==batch_size-1:\n",
        "                break\n",
        "            \n",
        "        i+=1\n",
        "        yield batch_data, batch_labels\n",
        "            \n",
        "        if i>=steps:\n",
        "            i=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUb2SwcOIs9k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg19 import preprocess_input\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import Input\n",
        "def build_model():\n",
        "    base_model = InceptionV3(weights='imagenet', include_top=False,input_shape=(224,224,3))\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(100, activation='relu')(x)\n",
        "    predictions = Dense(1, activation='sigmoid')(x)\n",
        "    \n",
        "    # this is the model we will train\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0eTcAyoIs9o",
        "colab_type": "code",
        "outputId": "283e45c9-5d9f-4f66-c897-be868a2c5b2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model =  build_model()\n",
        "# model.load_weights('weight1.h5')\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4271: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 8s 0us/step\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 100)          204900      global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            101         dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,007,785\n",
            "Trainable params: 21,973,353\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvapAggVIs9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "9ab02960-7660-49cc-f747-cf39c728175f"
      },
      "source": [
        "# opt = RMSprop(lr=0.0001, decay=1e-6)\n",
        "opt = Adam(lr=0.0001, decay=1e-5)\n",
        "es = EarlyStopping(patience=5)\n",
        "chkpt = ModelCheckpoint(filepath='best_model_todate', save_best_only=True, save_weights_only=True)\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'],optimizer=opt)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pgjjrFYIs9u",
        "colab_type": "code",
        "outputId": "035d5ab3-66ff-4189-9ee0-fb1cd3a860ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "batch_size = 32\n",
        "nb_epochs = 10\n",
        "\n",
        "# Get a train data generator\n",
        "train_data_gen = data_gen(data=train_data, batch_size=batch_size)\n",
        "\n",
        "# Define the number of training steps\n",
        "nb_train_steps = train_data.shape[0]//batch_size\n",
        "\n",
        "print(\"Number of training and validation steps: {} and {}\".format(nb_train_steps, len(valid_data)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training and validation steps: 163 and 16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLf_PRdKIs9x",
        "colab_type": "code",
        "outputId": "2e642088-c77e-4c7e-9fc7-3252162e8cdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "# Fit the model\n",
        "history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n",
        "                              validation_data=(valid_data, valid_labels),callbacks=[es, chkpt],\n",
        "                              class_weight={0:1.0, 1:0.4})"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "  5/163 [..............................] - ETA: 34:42 - loss: 0.3526 - acc: 0.6875"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-f7fb668d2300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit_generator(train_data_gen, epochs=nb_epochs, steps_per_epoch=nb_train_steps,\n\u001b[1;32m      2\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchkpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                               class_weight={0:1.0, 1:0.4})\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iW58GmBYIs91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for accuracy\n",
        "plt.figure(figsize=(12,6),)\n",
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy',color = 'white')\n",
        "plt.ylabel('accuracy',color = 'white')\n",
        "plt.xlabel('epoch',color = 'white')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.figure(figsize=(12,6))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss',color = 'white')\n",
        "plt.ylabel('loss',color = 'white')\n",
        "plt.xlabel('epoch',color = 'white')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFT4SzWMliuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing test data\n",
        "normal_cases_dir = test_dir / 'NORMAL'\n",
        "pneumonia_cases_dir = test_dir / 'PNEUMONIA'\n",
        "\n",
        "normal_cases = normal_cases_dir.glob('*.jpeg')\n",
        "pneumonia_cases = pneumonia_cases_dir.glob('*.jpeg')\n",
        "\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for img in normal_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = to_categorical(0, num_classes=2)\n",
        "    test_data.append(img)\n",
        "    test_labels.append(label)\n",
        "                      \n",
        "for img in pneumonia_cases:\n",
        "    img = cv2.imread(str(img))\n",
        "    img = cv2.resize(img, (224,224))\n",
        "    if img.shape[2] ==1:\n",
        "        img = np.dstack([img, img, img])\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = img.astype(np.float32)/255.\n",
        "    label = to_categorical(1, num_classes=2)\n",
        "    test_data.append(img)\n",
        "    test_labels.append(label)\n",
        "    \n",
        "\n",
        "test_data = np.array(test_data)\n",
        "test_labels = np.array(test_labels)\n",
        "\n",
        "print(\"Total number of test examples: \", test_data.shape)\n",
        "print(\"Total number of labels:\", test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnawrTMIl5JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluation on test dataset\n",
        "test_loss, test_score = model.evaluate(test_data, test_labels, batch_size=16)\n",
        "print(\"Loss on test set: \", test_loss)\n",
        "print(\"Accuracy on test set: \", test_score)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQvXBLeqmFtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predictions\n",
        "preds = model.predict(test_data, batch_size=16)\n",
        "preds = np.argmax(preds, axis=-1)\n",
        "\n",
        "# Original labels\n",
        "orig_test_labels = np.argmax(test_labels, axis=-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOlyeCH0mGiM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the confusion matrix\n",
        "cm  = confusion_matrix(orig_test_labels, preds)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm,figsize=(12,8), hide_ticks=True,cmap=plt.cm.Blues)\n",
        "plt.xticks(range(2), ['Normal', 'Pneumonia'], fontsize=14)\n",
        "plt.yticks(range(2), ['Normal', 'Pneumonia'], fontsize=14)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLmqoe9LmKo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate Precision and Recall\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "precision = tp/(tp+fp)\n",
        "recall = tp/(tp+fn)\n",
        "\n",
        "print(\"Recall of the model is {:.2f}\".format(recall))\n",
        "print(\"Precision of the model is {:.2f}\".format(precision))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Afm3Nc31mK-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve,auc\n",
        "\n",
        "predss = model.predict(test_data)\n",
        "\n",
        "fpr, tpr, threshold = roc_curve(orig_test_labels,  predss)\n",
        "roc_auc = auc(fpr,tpr)\n",
        "plt.plot(fpr,tpr,'b',label='AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc= 'lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cdLnFx6Ef8Q",
        "colab_type": "text"
      },
      "source": [
        "Ensemble\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNm2Ap_YEuY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsWoW7OTE4TI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create directory for models\n",
        "# os.makedirs('models')\n",
        "\n",
        "model.save_weights(filepath='model/weight1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "II4QU-qg2aEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " \n",
        "# make an ensemble prediction for multi-class classification\n",
        "def ensemble_predictions(members, testX):\n",
        "\t# make predictions\n",
        "\tyhats = [model.predict(testX) for model in members]\n",
        "\tyhats = array(yhats)\n",
        "\t# sum across ensemble members\n",
        "\tsummed = numpy.sum(yhats, axis=0)\n",
        "\t# argmax across classes\n",
        "\tresult = sigmoid(summed, axis=1)\n",
        "\treturn result\n",
        " \n",
        "# evaluate a specific number of members in an ensemble\n",
        "def evaluate_n_members(members, n_members, testX, testy):\n",
        "\t# select a subset of members\n",
        "\tsubset = members[:n_members]\n",
        "\tprint(len(subset))\n",
        "\t# make prediction\n",
        "\tyhat = ensemble_predictions(subset, testX)\n",
        "\t# calculate accuracy\n",
        "\treturn accuracy_score(testy, yhat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l95_624gNQ5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# list of model\n",
        "members = []\n",
        "# evaluate different numbers of ensembles\n",
        "scores = list()\n",
        "for i in range(1, n_members+1):\n",
        "\tscore = evaluate_n_members(members, i, testX, testy)\n",
        "\tprint('> %.3f' % score)\n",
        "\tscores.append(score)\n",
        "x_axis = [i for i in range(1, n_members+1)]\n",
        "pyplot.plot(x_axis, scores)\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}